{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x2dkUrFdrD5mRgNCY-qFwKDVIVQHPjYo",
      "authorship_tag": "ABX9TyOC0ggxzDL0LlM/mKQ5NVAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1940653868/AI-Job-Notes/blob/master/testgenmi_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEXmd5vixV8T",
        "outputId": "3ad525cc-7110-49d6-889b-1f6e03d07efa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1_NGtXoxdDY",
        "outputId": "84769fd4-8f5f-47da-816e-5ad27619851d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX5tBkCdmMPG",
        "outputId": "83bf1790-779f-4a00-ce7c-de728c2f3f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "streamlit 1.25.0 requires pillow<10,>=7.1.0, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip uninstall --quiet  pillow -y\n",
        "%pip install --quiet pydantic==2.3.0\n",
        "%pip install --upgrade --quiet  langchain-google-genai pillow langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "# AIzaSyD-qclTf76mTK6tdvQQvwI9C-7IK_tEY94\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")"
      ],
      "metadata": {
        "id": "zV6SavaV_dwJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate\n",
        ")\n",
        "from langchain.schema import (\n",
        "    HumanMessage\n",
        ")"
      ],
      "metadata": {
        "id": "NhK16h1exHDa"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "YzN00ellqzJZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
        "result = llm.invoke(\"Write a ballad about LangChain\")\n",
        "# print(result.content)"
      ],
      "metadata": {
        "id": "yT8x_9WwsE-K"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic.v1 import BaseModel, Field\n",
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import streamlit as st"
      ],
      "metadata": {
        "id": "sLJgrvU8vbuo"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
        "model(\n",
        "    [\n",
        "        SystemMessage(content=\"Answer only yes or no.\"),\n",
        "        HumanMessage(content=\"Is apple a fruit?\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q04FTHW0ygr8",
        "outputId": "1a289164-52dd-44ae-cd78-24ec644d15b6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Yes')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recipe_html(url):\n",
        "    response = requests.get(url)\n",
        "    html_markup = ''\n",
        "    if response.status_code == 200:\n",
        "        html_markup = response.text\n",
        "        soup = BeautifulSoup(html_markup, 'html.parser')\n",
        "\n",
        "        # Find the element with id 'recipe-single'\n",
        "        recipe_element = soup.find(id='recipe-single')\n",
        "\n",
        "        if recipe_element:\n",
        "            # Get the sanitized content within the 'recipe-single' element\n",
        "            html_markup = str(recipe_element)\n",
        "\n",
        "    return html_markup"
      ],
      "metadata": {
        "id": "Q_pC6Iy_yzD8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Ingredient(BaseModel):\n",
        "    name: str = Field(description=\"The name of the ingredient\")\n",
        "    quantity: str = Field(description=\"The specific unit of measurement corresponding to the quantity, such as grams, ounces, liters, etc.\")\n",
        "    unit: str = Field(description=\"The amount of the ingredient required for the recipe. This can be represented using various units such as grams, cups, teaspoons, etc.\")\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str = Field(description=\"The name of the recipe\")\n",
        "    ingredients: List[Ingredient] = Field(description=\"The list of ingredients for the recipe\")"
      ],
      "metadata": {
        "id": "3r_CvpfZy7mr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_by_chatgpt(openai_api_key, html_markup):\n",
        "    parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"Extract the recipe ingredients from the following HTML markup:\\n{html}.\\n{format_instructions}\\n\",\n",
        "        input_variables=[\"html\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "    )\n",
        "    # model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.0, openai_api_key=openai_api_key)\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
        "    output = model([ HumanMessage(content=prompt.format_prompt(html=html_markup).to_string()) ])\n",
        "\n",
        "    recipe = parser.parse(output.content)\n",
        "    return recipe"
      ],
      "metadata": {
        "id": "3HLyyCATy0dV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_url ='https://www.jamieoliver.com/recipes/liver-recipes/liver-bacon-onions/'\n",
        "html_markup = get_recipe_html(recipe_url)\n",
        "# print(html_markup)"
      ],
      "metadata": {
        "id": "v3qwmgT7_Wnl"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = 'None'\n",
        "recipe = parse_by_chatgpt(openai_api_key, html_markup)"
      ],
      "metadata": {
        "id": "El4xAiaNAivw"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8PhC_69G2Fr",
        "outputId": "dfe1830e-0a2c-47cf-c86f-881fb41a9f3d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Recipe(name='Liver, bacon & onions', ingredients=[Ingredient(name='red onion', quantity='Â½', unit='a'), Ingredient(name='fresh sage', quantity='2', unit='sprigs of'), Ingredient(name='sourdough bread', quantity='1', unit='slice of'), Ingredient(name='smoked higher-welfare streaky bacon', quantity='1', unit='rasher of'), Ingredient(name='higher-welfare calvesâ liver', quantity='125', unit='g slice of')])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    }
  ]
}